# Windows-compatible ML Docker Compose (CPU-only)
# For testing ML services without GPU support
version: '3.8'

services:
  # ML Prediction Server (CPU-only)
  ml-prediction-server:
    build:
      context: .
      dockerfile: Dockerfile.ml-cpu
    image: policycortex-ml-cpu:latest
    container_name: ml-prediction-server
    command: python3 -m ml_models.prediction_serving
    ports:
      - "8080:8080"  # API port
      - "9090:9090"  # Metrics port
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/policycortex
      - REDIS_URL=redis://redis:6379/0
      - ENABLE_GPU=false
      - CPU_ONLY=true
      - MODEL_CACHE_SIZE=5
      - INFERENCE_BATCH_SIZE=8
      - MAX_WAIT_MS=50
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - AZURE_TENANT_ID=${AZURE_TENANT_ID:-9ef5b184-d371-462a-bc75-5024ce8baff7}
      - AZURE_CLIENT_ID=${AZURE_CLIENT_ID:-1ecc95d1-e5bb-43e2-9324-30a17cb6b01c}
      - AZURE_CLIENT_SECRET=${AZURE_CLIENT_SECRET}
      - PYTHONUNBUFFERED=1
    volumes:
      - ml-models:/app/models
      - ml-checkpoints:/app/checkpoints
      - ml-logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - policycortex-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s

  # WebSocket Server
  ml-websocket-server:
    build:
      context: .
      dockerfile: Dockerfile.ml-cpu
    image: policycortex-ml-cpu:latest
    container_name: ml-websocket-server
    command: python3 /app/websocket_server.py
    ports:
      - "8765:8765"
    environment:
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/policycortex
      - PYTHONUNBUFFERED=1
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
    networks:
      - policycortex-network
    healthcheck:
      test: ["CMD", "python3", "-c", "import socket; s=socket.socket(); s.settimeout(5); s.connect(('localhost', 8765)); s.close()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # MLflow Tracking Server
  mlflow:
    image: python:3.10-slim
    container_name: mlflow
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=postgresql://postgres:postgres@postgres:5432/mlflow
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=/mlflow/artifacts
    volumes:
      - mlflow-artifacts:/mlflow/artifacts
    command: >
      sh -c "
      pip install mlflow==2.5.0 psycopg2-binary &&
      mlflow db upgrade postgresql://postgres:postgres@postgres:5432/mlflow &&
      mlflow server
      --backend-store-uri postgresql://postgres:postgres@postgres:5432/mlflow
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
      --port 5000
      "
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - policycortex-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s

  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: postgres-ml
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_MULTIPLE_DATABASES=policycortex,mlflow
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./backend/migrations:/docker-entrypoint-initdb.d:ro
      - ./scripts/init-multiple-databases.sh:/docker-entrypoint-initdb.d/00-init-multiple-databases.sh:ro
    networks:
      - policycortex-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d policycortex"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: redis-ml
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    networks:
      - policycortex-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Prometheus for Metrics (Optional)
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus-ml
    ports:
      - "9091:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus-ml.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    networks:
      - policycortex-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    profiles:
      - monitoring  # Only start with --profile monitoring

volumes:
  ml-models:
    driver: local
  ml-checkpoints:
    driver: local
  ml-logs:
    driver: local
  mlflow-artifacts:
    driver: local
  postgres-data:
    driver: local
  redis-data:
    driver: local
  prometheus-data:
    driver: local

networks:
  policycortex-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.21.0.0/16